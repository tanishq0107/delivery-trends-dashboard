# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from pytrends.request import TrendReq
from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
import requests

# ---------------------------
# 1. Page Config
# ---------------------------
st.set_page_config(
    page_title="Search Before Action: Delivery Wars",
    page_icon="üçî",
    layout="wide"
)

st.title("Search Before Action: Google Trends & India‚Äôs Delivery Wars")
st.markdown("### Swiggy üü† | Zomato üî¥ | Blinkit üü¢")

# ---------------------------
# 2. Helper Functions
# ---------------------------

@st.cache_data(ttl=86400)
def load_trends():
    pytrends = TrendReq(hl="en-IN", tz=330)
    kw_list = ["Swiggy", "Zomato", "Blinkit"]
    pytrends.build_payload(kw_list, timeframe="today 5-y", geo="IN")
    data = pytrends.interest_over_time()
    if "isPartial" in data.columns:
        data = data.drop(columns=["isPartial"])
    data = data.reset_index()

    geo = pytrends.interest_by_region(resolution="REGION", inc_low_vol=False, inc_geo_code=False)
    geo = geo.reset_index()
    geo = geo.rename(columns={"geoName": "state"})
    return data, geo

@st.cache_data
def load_geojson():
    url = "https://raw.githubusercontent.com/geohacker/india/master/state/india_states.geojson"
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        return r.json()
    except Exception:
        st.warning("‚ö†Ô∏è Could not fetch India GeoJSON, using local fallback.")
        # Minimal GeoJSON fallback for major states
        local_geojson = {
            "type": "FeatureCollection",
            "features": [
                {"type": "Feature", "properties": {"ST_NM": "Delhi"}, "geometry": {"type": "Polygon","coordinates": [[[77.0,28.5],[77.5,28.5],[77.5,28.8],[77.0,28.8],[77.0,28.5]]]}},
                {"type": "Feature", "properties": {"ST_NM": "Maharashtra"}, "geometry": {"type": "Polygon","coordinates": [[[73.0,18.0],[75.5,18.0],[75.5,20.0],[73.0,20.0],[73.0,18.0]]]}},
                {"type": "Feature", "properties": {"ST_NM": "Karnataka"}, "geometry": {"type": "Polygon","coordinates": [[[75.0,11.5],[77.5,11.5],[77.5,15.0],[75.0,15.0],[75.0,11.5]]]}},
                {"type": "Feature", "properties": {"ST_NM": "Tamil Nadu"}, "geometry": {"type": "Polygon","coordinates": [[[78.0,10.0],[80.5,10.0],[80.5,13.0],[78.0,13.0],[78.0,10.0]]]}},
                {"type": "Feature", "properties": {"ST_NM": "Uttar Pradesh"}, "geometry": {"type": "Polygon","coordinates": [[[79.0,26.0],[82.0,26.0],[82.0,28.5],[79.0,28.5],[79.0,26.0]]]}}
            ]
        }
        return local_geojson

def generate_pdf(df, geo_df):
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    c.setFont("Helvetica-Bold", 14)
    c.drawString(50, 800, "Google Trends: Delivery Wars (Swiggy vs Zomato vs Blinkit)")
    c.setFont("Helvetica", 10)
    c.drawString(50, 770, f"Swiggy Peak: {df['Swiggy'].max()} index")
    c.drawString(50, 755, f"Zomato Peak: {df['Zomato'].max()} index")
    c.drawString(50, 740, f"Blinkit Peak: {df['Blinkit'].max()} index")
    c.drawString(50, 710, "Top 5 States by Blinkit:")
    top_states = geo_df.sort_values("Blinkit", ascending=False).head(5)
    y = 695
    for i, row in top_states.iterrows():
        c.drawString(60, y, f"{row['state']} ‚Üí {row['Blinkit']}")
        y -= 15
    c.showPage()
    c.save()
    buffer.seek(0)
    return buffer

# ---------------------------
# 3. Load Data
# ---------------------------
try:
    df, geo_df = load_trends()
except Exception:
    st.warning("‚ö†Ô∏è Could not fetch live data, using dummy data.")
    dates = pd.date_range("2019-01-01", periods=250, freq="W")
    df = pd.DataFrame({
        "date": dates,
        "Swiggy": np.random.randint(30, 90, size=len(dates)),
        "Zomato": np.random.randint(40, 95, size=len(dates)),
        "Blinkit": np.random.randint(20, 100, size=len(dates))
    })
    geo_df = pd.DataFrame({
        "state": ["Delhi", "Karnataka", "Maharashtra", "Tamil Nadu", "Uttar Pradesh"],
        "Swiggy": [70, 55, 60, 80, 50],
        "Zomato": [65, 70, 75, 60, 55],
        "Blinkit": [85, 40, 50, 30, 25]
    })

# ---------------------------
# 4. Sidebar Navigation
# ---------------------------
st.sidebar.title("üìä Dashboard Navigation")
page = st.sidebar.radio("Go to:", [
    "Overview",
    "Trends Over Time",
    "Regional Insights",
    "Search Intent",
    "Stats & Correlations",
    "Challenges & Story"
])

# ---------------------------
# 5. Pages
# ---------------------------

if page == "Overview":
    st.subheader("üìå Big Picture: Who‚Äôs Winning?")
    col1, col2, col3 = st.columns(3)
    col1.metric("Swiggy Peak", f"{df['Swiggy'].max()} index")
    col2.metric("Zomato Peak", f"{df['Zomato'].max()} index")
    col3.metric("Blinkit Peak", f"{df['Blinkit'].max()} index")
    fig = px.line(df, x="date", y=["Swiggy","Zomato","Blinkit"], title="üìà Search Popularity Over Time (5 years)")
    st.plotly_chart(fig, use_container_width=True)
    st.download_button("‚¨áÔ∏è Download Time-Series (CSV)", df.to_csv(index=False).encode("utf-8"), "delivery_trends_timeseries.csv", "text/csv")
    pdf_buffer = generate_pdf(df, geo_df)
    st.download_button("‚¨áÔ∏è Download Summary (PDF)", pdf_buffer, "delivery_trends_summary.pdf", "application/pdf")

elif page == "Trends Over Time":
    st.subheader("üìà Interactive Time-Series")
    window = st.slider("Smoothing Window (weeks):", 1, 8, 4)
    df_smooth = df.copy()
    df_smooth[["Swiggy","Zomato","Blinkit"]] = df_smooth[["Swiggy","Zomato","Blinkit"]].rolling(window).mean()
    fig = px.line(df_smooth, x="date", y=["Swiggy","Zomato","Blinkit"], title="Search Trends (Smoothed)")
    st.plotly_chart(fig, use_container_width=True)

elif page == "Regional Insights":
    st.subheader("üó∫Ô∏è Regional Heatmap Comparison (India States)")
    india_states = load_geojson()
    # Standardize state names
    state_mapping = {
        "NCT": "Delhi",
        "Orissa": "Odisha",
        "Uttaranchal": "Uttarakhand",
        "Jammu & Kashmir": "Jammu and Kashmir",
        "Andaman & Nicobar Islands": "Andaman & Nicobar",
        "Dadra and Nagar Haveli": "Dadra & Nagar Haveli",
        "Daman and Diu": "Daman & Diu",
        "Arunanchal Pradesh": "Arunachal Pradesh"
    }
    geo_df["state"] = geo_df["state"].replace(state_mapping)
    geo_df["state"] = geo_df["state"].str.title().str.strip()
    col1, col2, col3 = st.columns(3)
    apps = ["Swiggy", "Zomato", "Blinkit"]
    for col, app in zip([col1, col2, col3], apps):
        fig = px.choropleth(
            geo_df,
            geojson=india_states,
            featureidkey="properties.ST_NM",
            locations="state",
            color=app,
            hover_name="state",
            color_continuous_scale="YlOrRd",
            title=f"{app}"
        )
        fig.update_geos(fitbounds="locations", visible=False)
        col.plotly_chart(fig, use_container_width=True)
    st.download_button("‚¨áÔ∏è Download Regional Insights (CSV)", geo_df.to_csv(index=False).encode("utf-8"), "delivery_trends_states.csv", "text/csv")

elif page == "Search Intent":
    st.subheader("üîç What Are People Searching?")
    pytrends = TrendReq(hl="en-IN", tz=330)
    app_choice = st.selectbox("Choose App:", ["Swiggy", "Zomato", "Blinkit"])
    try:
        pytrends.build_payload([app_choice], timeframe="today 12-m", geo="IN")
        related = pytrends.related_queries()
        top_queries = related[app_choice]["top"].head(10)
        st.write("Top Queries:")
        st.dataframe(top_queries)
        text = " ".join(top_queries["query"].dropna().tolist())
        wc = WordCloud(width=800, height=400, background_color="white").generate(text)
        fig, ax = plt.subplots(figsize=(10,5))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    except Exception:
        st.warning("‚ö†Ô∏è Could not fetch related queries. Showing placeholder.")
        placeholder_queries = ["Swiggy coupon","Swiggy near me","Zomato pizza","Blinkit near me"]
        text = " ".join(placeholder_queries)
        wc = WordCloud(width=800, height=400, background_color="white").generate(text)
        fig, ax = plt.subplots(figsize=(10,5))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)

elif page == "Stats & Correlations":
    st.subheader("üìä Stats & Correlations")
    corr = df[["Swiggy","Zomato","Blinkit"]].corr()
    st.dataframe(corr)
    st.latex(r"Z = \frac{x - \mu}{\sigma}")
    st.latex(r"\text{Correlation}(X,Y) = \frac{\text{cov}(X,Y)}{\sigma_X \sigma_Y}")
    st.latex(r"\text{Lag Correlation} = \text{Corr}(X_t, Y_{t+k})")

elif page == "Challenges & Story":
    st.subheader("‚ö° Challenges & Eureka Moments")
    st.markdown("**Challenges:**")
    st.markdown("- Relative Scaling ‚Üí anchored to 'food delivery'")
    st.markdown("- Festival Spikes ‚Üí smoothed via rolling averages")
    st.markdown("- Sparse Data ‚Üí focused on top 10 states")
    st.info("üí° Eureka: Blinkit‚Äôs Delhi surge appeared in Trends months before headlines!")

st.sidebar.markdown("---")
st.sidebar.markdown("Made with ‚ù§Ô∏è using Streamlit, PyTrends, Plotly & WordCloud")
